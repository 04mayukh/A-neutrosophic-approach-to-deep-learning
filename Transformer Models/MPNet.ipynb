{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "semeval_2017_task_4_transformers_mpnet Github.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aeQYHT_Bs_8E"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYIyBaHWoEqo"
      },
      "source": [
        "pip install keras-self-attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bx_4MDnJXcJ"
      },
      "source": [
        "!pip install emoji"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqX4j-pSKRWa"
      },
      "source": [
        "!pip install ekphrasis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXiFH_-DCKjv"
      },
      "source": [
        "!pip install transformers==4.2.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCwhNaO9JXcX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import os\n",
        "from collections import Counter\n",
        "\n",
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Urfy-aPJXcd"
      },
      "source": [
        "text_processor = TextPreProcessor(\n",
        "    # terms that will be normalized\n",
        "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
        "        'time', 'url', 'date', 'number'],\n",
        "    # terms that will be annotated\n",
        "    annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
        "        'emphasis', 'censored'},\n",
        "    fix_html=True,  # fix HTML tokens\n",
        "    \n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for word segmentation \n",
        "    segmenter=\"twitter\", \n",
        "    \n",
        "    # corpus from which the word statistics are going to be used \n",
        "    # for spell correction\n",
        "    corrector=\"twitter\", \n",
        "    \n",
        "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
        "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
        "    spell_correct_elong=True,  # spell correction for elongated words\n",
        "    \n",
        "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
        "    # the tokenizer, should take as input a string and return a list of tokens\n",
        "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
        "    \n",
        "    # list of dictionaries, for replacing tokens extracted from the text,\n",
        "    # with other expressions. You can pass more than one dictionaries.\n",
        "    dicts=[emoticons]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U40gpHRJXci"
      },
      "source": [
        "def print_text(texts,i,j):\n",
        "    for u in range(i,j):\n",
        "        print(texts[u])\n",
        "        print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtySfy-O-Va2"
      },
      "source": [
        "df_1 = pd.read_csv('/content/drive/My Drive/Semeval 2017/twitter-2016train-A.txt', delimiter='\\t', encoding='utf-8', header=None)\n",
        "# print(df_1.head(5)) #last N rows\n",
        "# print(len(df_1))\n",
        "\n",
        "df_2 = pd.read_csv('/content/drive/My Drive/Semeval 2017/twitter-2016test-A.txt', delimiter='\\t', encoding='utf-8', header=None)\n",
        "# print(df_2.head(5)) #last N rows\n",
        "# print(len(df_2))\n",
        "\n",
        "df_3 = pd.read_csv('/content/drive/My Drive/Semeval 2017/twitter-2016devtest-A.txt', delimiter='\\t', encoding='utf-8', header=None)\n",
        "# print(df_3.head(5)) #last N rows\n",
        "# print(len(df_3))\n",
        "\n",
        "df_4 = pd.read_csv('/content/drive/My Drive/Semeval 2017/twitter-2016dev-A.txt', delimiter='\\t', encoding='utf-8', header=None)\n",
        "# print(df_4.head(5)) #last N rows\n",
        "# print(len(df_4))\n",
        "\n",
        "df_5 = pd.read_csv('/content/drive/My Drive/Semeval 2017/twitter-2015train-A.txt', delimiter='\\t', encoding='utf-8', header=None)\n",
        "# print(df_5.head(5)) #last N rows\n",
        "# print(len(df_5))\n",
        "\n",
        "df_6 = pd.read_csv('/content/drive/My Drive/Semeval 2017/twitter-2015test-A.txt', delimiter='\\t', encoding='utf-8', header=None)\n",
        "# print(df_6.head(5)) #last N rows\n",
        "# print(len(df_6))\n",
        "\n",
        "df_7 = pd.read_csv('/content/drive/My Drive/Semeval 2017/twitter-2014test-A.txt', delimiter='\\t', encoding='utf-8', header=None)\n",
        "# print(df_7.head(5)) #last N rows\n",
        "# print(len(df_7))\n",
        "\n",
        "df_8 = pd.read_csv('/content/drive/My Drive/Semeval 2017/twitter-2014sarcasm-A.txt', delimiter='\\t', encoding='utf-8', header=None)\n",
        "# print(df_8.head(5)) #last N rows\n",
        "# print(len(df_8))\n",
        "\n",
        "df_9 = pd.read_csv('/content/drive/My Drive/Semeval 2017/twitter-2013train-A.txt', delimiter='\\t', encoding='utf-8', header=None)\n",
        "# print(df_9.head(5)) #last N rows\n",
        "# print(len(df_9))\n",
        "\n",
        "df_10 = pd.read_csv('/content/drive/My Drive/Semeval 2017/twitter-2013test-A.txt', delimiter='\\t', encoding='utf-8', header=None)\n",
        "# print(df_10.head(5)) #last N rows\n",
        "# print(len(df_10))\n",
        "\n",
        "df_11 = pd.read_csv('/content/drive/My Drive/Semeval 2017/twitter-2013dev-A.txt', delimiter='\\t', encoding='utf-8', header=None)\n",
        "# print(df_11.head(5)) #last N rows\n",
        "# print(len(df_11))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpzhcecp3o0c"
      },
      "source": [
        "<h2>Balancing the data</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAsanMo83ndl"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df = df.append(df_1, ignore_index = True)\n",
        "df = df.append(df_2, ignore_index = True)\n",
        "df = df.append(df_3, ignore_index = True)\n",
        "df = df.append(df_4, ignore_index = True)\n",
        "\n",
        "df = df.append(df_5, ignore_index = True)\n",
        "df = df.append(df_6, ignore_index = True)\n",
        "df = df.append(df_7, ignore_index = True)\n",
        "df = df.append(df_8, ignore_index = True)\n",
        "\n",
        "df = df.append(df_9, ignore_index = True)\n",
        "df = df.append(df_10, ignore_index = True)\n",
        "df = df.append(df_11, ignore_index = True)\n",
        "\n",
        "print(df.head(5))\n",
        "print(len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWi1U6wuJXcu"
      },
      "source": [
        "# Testing for null values\n",
        "# lol = np.asarray(df_[1].isnull())\n",
        "\n",
        "# for i in range(0,len(lol)):\n",
        "#     if lol[i]:\n",
        "#         print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFCXYFuQBg7w"
      },
      "source": [
        "print(len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRuDyI63Be8M"
      },
      "source": [
        "text_array = df[2]\n",
        "labels = df[1]\n",
        "print(\"Length of training data: \",len(text_array))\n",
        "print_text(text_array,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WW4OKUrkClTN"
      },
      "source": [
        "df_val = pd.read_csv('/content/drive/My Drive/Semeval 2017/Test/SemEval2017-task4-test.subtask-A.english.txt', delimiter='\\n', encoding='utf-8', header=None)\n",
        "print(df_val.tail(5)) #last N rows\n",
        "print(len(df_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9yK3oN1NEWu"
      },
      "source": [
        "lol = []\n",
        "test_set = np.asarray(df_val[0])\n",
        "for i in range(0,len(df_val)):\n",
        "    temp = np.asarray(test_set[i].split(\"\\t\"))\n",
        "    temp = temp.reshape((3))\n",
        "    lol.append(temp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2vo3_e0QxDP"
      },
      "source": [
        "df_val = pd.DataFrame(lol)\n",
        "df_val.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5PUdxUFCiK9"
      },
      "source": [
        "text_array_val = df_val[2]\n",
        "labels_val = df_val[1]\n",
        "print(\"Length of validation data: \",len(text_array_val))\n",
        "print_text(text_array_val,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nNEIPu89oP4"
      },
      "source": [
        "print(Counter(labels))\n",
        "print(Counter(labels_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5MQYHo5JXdJ"
      },
      "source": [
        "#removing website names\n",
        "def remove_website(text):\n",
        "    return \" \".join([word if re.search(\"r'https?://\\S+|www\\.\\S+'|((?i).com$|.co|.net)\",word)==None else \"\" for word in text.split(\" \") ])\n",
        "\n",
        "# Training set \n",
        "text_array = text_array.apply(lambda text: remove_website(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Validation set \n",
        "text_array_val = text_array_val.apply(lambda text: remove_website(text))\n",
        "print_text(text_array_val,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4rE3iyeJXdS"
      },
      "source": [
        "# Functions for chat word conversion\n",
        "f = open(\"/content/drive/My Drive/Semeval 2017/slang.txt\", \"r\")\n",
        "chat_words_str = f.read()\n",
        "chat_words_map_dict = {}\n",
        "chat_words_list = []\n",
        "\n",
        "for line in chat_words_str.split(\"\\n\"):\n",
        "    if line != \"\":\n",
        "        cw = line.split(\"=\")[0]\n",
        "        cw_expanded = line.split(\"=\")[1]\n",
        "        chat_words_list.append(cw)\n",
        "        chat_words_map_dict[cw] = cw_expanded\n",
        "chat_words_list = set(chat_words_list)\n",
        "\n",
        "def chat_words_conversion(text):\n",
        "    new_text = []\n",
        "    for w in text.split():\n",
        "        if w.upper() in chat_words_list:\n",
        "            new_text.append(chat_words_map_dict[w.upper()])\n",
        "        else:\n",
        "            new_text.append(w)\n",
        "    return \" \".join(new_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcFQPohcJXdZ"
      },
      "source": [
        "# Chat word conversion\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: chat_words_conversion(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"********************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_val = text_array_val.apply(lambda text: chat_words_conversion(text))\n",
        "print_text(text_array_val,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTBeDB-YEggQ"
      },
      "source": [
        "os.chdir(\"/content/drive/My Drive/Semeval 2017\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL-opLGAJXde"
      },
      "source": [
        "#Function for emoticon conversion\n",
        "from emoticons import EMOTICONS\n",
        "\n",
        "def convert_emoticons(text):\n",
        "    for emot in EMOTICONS:\n",
        "        text = re.sub(u'('+emot+')', \" \".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
        "    return text\n",
        "\n",
        "\n",
        "#testing the emoticon function\n",
        "text = \"Hello :-) :-)\"\n",
        "text = convert_emoticons(text)\n",
        "print(text + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVXaSmvRJXdi"
      },
      "source": [
        "# Emoticon conversion\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: convert_emoticons(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**********************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_val = text_array_val.apply(lambda text: convert_emoticons(text))\n",
        "print_text(text_array_val,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LOLUlHLEl3M"
      },
      "source": [
        "os.chdir(\"/content\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teGGeHMQJXdn"
      },
      "source": [
        "# FUnction for removal of emoji\n",
        "import emoji\n",
        "\n",
        "def convert_emojis(text):\n",
        "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "    text = re.sub(\"_|-\",\" \",text)\n",
        "    return text\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: convert_emojis(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_val = text_array_val.apply(lambda text: convert_emojis(text))\n",
        "print_text(text_array_val,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acBMRaGRJXdt"
      },
      "source": [
        "# Ekphrasis pipe for text pre-processing\n",
        "def ekphrasis_pipe(sentence):\n",
        "    cleaned_sentence = \" \".join(text_processor.pre_process_doc(sentence))\n",
        "    return cleaned_sentence\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: ekphrasis_pipe(text))\n",
        "print(\"Training set completed.......\")\n",
        "#Validation set\n",
        "text_array_val = text_array_val.apply(lambda text: ekphrasis_pipe(text))\n",
        "print(\"Test set completed.......\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_L3dXj9nJXdz"
      },
      "source": [
        "print_text(text_array,0,10)\n",
        "print(\"************************************************************************\")\n",
        "print_text(text_array_val,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIaQRw7hJXd4"
      },
      "source": [
        "# Removing unnecessary punctuations\n",
        "PUNCT_TO_REMOVE = \"\\\"$%&'()+,-./;=[\\]^_`{|}~\"\n",
        "def remove_punctuation(text):\n",
        "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
        "\n",
        "# Training set\n",
        "text_array = text_array.apply(lambda text: remove_punctuation(text))\n",
        "print_text(text_array,0,10)\n",
        "\n",
        "print(\"********************************************************************\")\n",
        "\n",
        "# Validation set\n",
        "text_array_val = text_array_val.apply(lambda text: remove_punctuation(text))\n",
        "print_text(text_array_val,0,10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ3ob-YFJXd8"
      },
      "source": [
        "# Finding length of longest array\n",
        "maxLen = len(max(text_array,key = lambda text: len(text.split(\" \"))).split(\" \"))\n",
        "print(maxLen)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KZzrm_BJXeD"
      },
      "source": [
        "u = lambda text: len(text.split(\" \"))\n",
        "sentence_lengths = []\n",
        "for x in text_array:\n",
        "    sentence_lengths.append(u(x))\n",
        "print(sorted(sentence_lengths)[-800:])\n",
        "print(len(sentence_lengths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYE6TcR0JXea"
      },
      "source": [
        "# Count of each label in dataset\n",
        "from collections import Counter\n",
        "\n",
        "# Printing training set counts for analysis\n",
        "print(\"Elements: \",set(labels))\n",
        "print(\"Length: \",len(labels))\n",
        "print(Counter(labels))\n",
        "\n",
        "print(\"**************************************************************************\")\n",
        "\n",
        "# Printing validation set counts for analysis\n",
        "print(\"Elements: \",set(labels_val))\n",
        "print(\"Length: \",len(labels_val))\n",
        "print(Counter(labels_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhDuYnCbJXee"
      },
      "source": [
        "Y = []\n",
        "Y_val = []\n",
        "\n",
        "# Training set    \n",
        "for i in range(0,len(labels)):\n",
        "    if(labels[i] == 'neutral'):\n",
        "        Y.append(0)\n",
        "    if(labels[i] == 'positive'):\n",
        "        Y.append(1)\n",
        "    if(labels[i] == 'negative'):\n",
        "        Y.append(2)\n",
        "\n",
        "\n",
        "# Validation set\n",
        "for i in range(0,len(labels_val)):\n",
        "    if(labels_val[i] == 'neutral'):\n",
        "        Y_val.append(0)\n",
        "    if(labels_val[i] == 'positive'):\n",
        "        Y_val.append(1)\n",
        "    if(labels_val[i] == 'negative'):\n",
        "        Y_val.append(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTD-IVLRJXej"
      },
      "source": [
        "print(len(Y),len(Y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf17nyOaJXen"
      },
      "source": [
        "print(Counter(Y))\n",
        "print(Counter(Y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihJqcUHpJXer"
      },
      "source": [
        "# Testing the conversion into integers\n",
        "for i in range(310,320):\n",
        "    print(text_array_val[i])\n",
        "    print(labels_val[i],Y_val[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhNUihGeJXev"
      },
      "source": [
        "# Verifying train set \n",
        "X = np.asarray(list(text_array))\n",
        "Y = np.asarray(list(Y))\n",
        "labels = np.asarray(list(labels))\n",
        "print(type(X))\n",
        "print(type(Y))\n",
        "print(type(labels))\n",
        "print(np.shape(X),np.shape(Y),np.shape(labels))\n",
        "\n",
        "# Verifying validation set\n",
        "X_val = np.asarray(list(text_array_val))\n",
        "Y_val = np.asarray(list(Y_val))\n",
        "labels_val = np.asarray(list(labels_val))\n",
        "print(type(X_val))\n",
        "print(type(Y_val))\n",
        "print(type(labels_val))\n",
        "print(np.shape(X_val),np.shape(Y_val),np.shape(labels_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-FOp4xwJXfz"
      },
      "source": [
        "index = 824\n",
        "print(X[index])\n",
        "print(labels[index])\n",
        "print(Y[index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqGoNZDBJXf7"
      },
      "source": [
        "print(type(X))\n",
        "print(type(Y))\n",
        "print(np.shape(X),np.shape(Y),np.shape(labels))\n",
        "print(np.shape(X_val),np.shape(Y_val),np.shape(labels_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0PeQc9AJXf_"
      },
      "source": [
        "# Converting to one hot vectors\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)] #u[Y] helps to index each element of Y index at u. U here is a class array\n",
        "    return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8yc2wj5JXgF"
      },
      "source": [
        "Y_oh_train = convert_to_one_hot(np.array(Y), C = 3)\n",
        "Y_oh_val = convert_to_one_hot(np.array(Y_val), C = 3)\n",
        "\n",
        "print(np.shape(Y_oh_train))\n",
        "index = 310\n",
        "print(labels[index], Y[index], \"is converted into one hot\", Y_oh_train[index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7_7y3eHJXgI"
      },
      "source": [
        "\n",
        "\n",
        "<h2>Tensorflow Model</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap4tHjaMEbB7"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import string\r\n",
        "from nltk.corpus import stopwords\r\n",
        "import re\r\n",
        "import os\r\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TphUcxSmEFYz"
      },
      "source": [
        "from transformers import RobertaTokenizerFast, TFRobertaModel, TFBertModel, BertTokenizerFast, ElectraTokenizerFast, TFElectraModel, AlbertTokenizerFast, TFAlbertModel, XLNetTokenizerFast, TFXLNetModel, MPNetTokenizerFast, TFMPNetModel\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.metrics import f1_score\r\n",
        "from keras_self_attention import SeqSelfAttention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhUZe7iiJXgP"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udEBhQ1FEfNi"
      },
      "source": [
        "\r\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\r\n",
        "\r\n",
        "tf.config.experimental_connect_to_cluster(resolver)\r\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\r\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YSpgiV-E3nW"
      },
      "source": [
        "tokenizer = MPNetTokenizerFast.from_pretrained(\"microsoft/mpnet-base\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcppSX7DE4sY"
      },
      "source": [
        "X = list(X)\r\n",
        "X_val = list(X_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyCi4h7gE4pE"
      },
      "source": [
        "train_encodings = tokenizer(X, max_length=80, truncation=True, padding=\"max_length\", return_tensors='tf')\r\n",
        "val_encodings = tokenizer(X_val, max_length=80, truncation=True, padding=\"max_length\", return_tensors='tf')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn3d_2-HE4m2"
      },
      "source": [
        "print(np.shape(train_encodings[\"input_ids\"]))\r\n",
        "print(np.shape(val_encodings[\"input_ids\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi7beAXQE4ki"
      },
      "source": [
        "print(train_encodings[\"input_ids\"][0])\r\n",
        "print(\"***************************************************************************\")\r\n",
        "print(val_encodings[\"input_ids\"][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWLzQYP1zTQS"
      },
      "source": [
        "# This is the best model\n",
        "def Offense_classifier(input_shape):\n",
        "    \"\"\"\n",
        "    Function creating the Emojify-v2 model's graph.\n",
        "    \n",
        "    Arguments:\n",
        "    input_shape -- shape of the input, usually (max_len,)\n",
        "    word_to_vec_map -- dictionary mapping every word in a vocabulary into its 50-dimensional vector representation\n",
        "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
        "\n",
        "    Returns:\n",
        "    model -- a model instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    model = TFMPNetModel.from_pretrained('microsoft/mpnet-base')\n",
        "    layer = model.layers[0]\n",
        "\n",
        "    # Define sentence_indices as the input of the graph, it should be of shape input_shape and dtype 'int32' (as it contains indices).\n",
        "    inputs = keras.Input(shape=input_shape, dtype='int32')\n",
        "    input_masks = keras.Input(shape=input_shape, dtype='int32')\n",
        "    \n",
        "    embeddings = layer([inputs, input_masks])[0][:,0,:]\n",
        "    \n",
        "    # embeddings = keras.layers.GaussianNoise(0.2)(embeddings)\n",
        "\n",
        "    # embeddings = keras.layers.Dropout(0.3)(embeddings)\n",
        "\n",
        "    # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
        "    # Be careful, the returned output should be a batch of sequences.\n",
        "    # lstm_one = keras.layers.Bidirectional(keras.layers.LSTM(150, return_sequences=True, recurrent_dropout=0.25, dropout=0.2)) \n",
        "    # X = lstm_one(embeddings)\n",
        "    # X = keras.layers.Dropout(0.2)(X)\n",
        "\n",
        "    # lstm_two = keras.layers.Bidirectional(keras.layers.LSTM(150, return_sequences=True, recurrent_dropout=0.25, dropout=0.2)) \n",
        "    # X = lstm_two(X)\n",
        "    # X = keras.layers.Dropout(0.2)(X)\n",
        "\n",
        "    # # *************Attention*******************\n",
        "    # X = SeqSelfAttention(attention_activation='elu')(X)\n",
        "    # # ****************Attention*******************\n",
        "\n",
        "    # post_activation_GRU_cell = keras.layers.GRU(64, return_sequences = False, recurrent_dropout=0.25, dropout=0.2)\n",
        "    # X = post_activation_GRU_cell(X)\n",
        "\n",
        "    X = keras.layers.Dense(32,activation='elu',kernel_regularizer=keras.regularizers.l2(0.0001))(embeddings)\n",
        "\n",
        "    X = keras.layers.BatchNormalization(momentum=0.99, epsilon=0.001, center=True, scale=True)(X)\n",
        "\n",
        "    X = keras.layers.Dense(3,activation='tanh',kernel_regularizer=keras.regularizers.l2(0.0001))(X)\n",
        "\n",
        "    \n",
        "    # Add a sigmoid activation\n",
        "    X = keras.layers.Activation('softmax')(X)\n",
        "    \n",
        "    # Create Model instance which converts sentence_indices into X.\n",
        "    model = keras.Model(inputs=[inputs,input_masks], outputs=[X])\n",
        "    \n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4iKjQbtN7Jb"
      },
      "source": [
        "model = Offense_classifier((80,))\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEwZdircHVZ2"
      },
      "source": [
        "strategy = tf.distribute.TPUStrategy(resolver)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5z_U7gcPNaG"
      },
      "source": [
        "class EvaluationMetric(keras.callbacks.Callback):   \r\n",
        "    \r\n",
        "    def __init__(self, trial_encodings, trial_masks, Y_val):\r\n",
        "        super(EvaluationMetric, self).__init__()\r\n",
        "        self.trial_encodings = trial_encodings\r\n",
        "        self.trial_masks = trial_masks\r\n",
        "        self.Y_val = Y_val\r\n",
        "    \r\n",
        "    def on_epoch_begin(self, epoch, logs={}):\r\n",
        "        print(\"\\nTraining...\")\r\n",
        "\r\n",
        "    def on_epoch_end(self, epoch, logs={}):\r\n",
        "        print(\"\\nEvaluating...\")\r\n",
        "        trial_prediction = self.model.predict([self.trial_encodings,self.trial_masks])\r\n",
        "        \r\n",
        "        pred = []\r\n",
        "        for i in range(0,len(self.Y_val)):\r\n",
        "            num = np.argmax(trial_prediction[i])\r\n",
        "            pred.append(num)\r\n",
        "        \r\n",
        "        from sklearn.metrics import classification_report\r\n",
        "        print(classification_report(Y_val, pred, digits=3))\r\n",
        "        \r\n",
        "evaluation_metric = EvaluationMetric(val_encodings[\"input_ids\"], val_encodings[\"attention_mask\"], Y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygp8tTFKIKzW"
      },
      "source": [
        "with strategy.scope():\r\n",
        "    model = Offense_classifier((80,))\r\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-5)\r\n",
        "    loss_fun = [\r\n",
        "          tf.keras.losses.CategoricalCrossentropy(from_logits=True)\r\n",
        "    ]\r\n",
        "    metric = ['acc']\r\n",
        "    model.compile(optimizer=optimizer, loss=loss_fun, metrics=metric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6DrFcOmIyjg"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxU1g0UdJXhE"
      },
      "source": [
        "checkpoint = ModelCheckpoint(filepath='/content/neutro-mpnet.{epoch:03d}.h5',\n",
        "                                 verbose = 0,\n",
        "                                 save_weights_only=True,\n",
        "                                 epoch=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oU_7l0P2GWl"
      },
      "source": [
        "c = Counter(Y)\n",
        "print(c)\n",
        "print(c.keys())\n",
        "neutral = c[0]\n",
        "pos = c[1]\n",
        "neg = c[2]\n",
        "total = pos+neg+neutral\n",
        "print(neutral,pos,neg,total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gprkw9zj1gpp"
      },
      "source": [
        "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
        "# The sum of the weights of all examples stays the same.\n",
        "maxi = max(pos,neg,neutral)\n",
        "weight_for_0 = (maxi / (maxi+neutral))\n",
        "weight_for_1 = (maxi / (maxi+pos))\n",
        "weight_for_2 = (maxi / (maxi+neg))\n",
        "\n",
        "class_weight_ = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
        "print('Weight for class 2: {:.2f}'.format(weight_for_2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5riWhojdbwsG"
      },
      "source": [
        "history = model.fit(\r\n",
        "    x = [train_encodings[\"input_ids\"], train_encodings[\"attention_mask\"]],\r\n",
        "    y = Y_oh_train,\r\n",
        "    validation_data = ([val_encodings[\"input_ids\"],val_encodings[\"attention_mask\"]],Y_oh_val),\r\n",
        "    callbacks = [evaluation_metric, checkpoint],\r\n",
        "    batch_size = 32,\r\n",
        "    shuffle=True,\r\n",
        "    epochs=6,\r\n",
        "    class_weight = class_weight_\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0Ok9EYPgN9V"
      },
      "source": [
        "# plot_model(model, to_file=\"model.png\", show_shapes=True, show_layer_names=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKrBeHKTNaDy"
      },
      "source": [
        "model.load_weights(\"/content/drive/MyDrive/semeval 17 transformer weights/neutro-mpnet.004.h5\")\n",
        "# model.save_weights(\"/content/drive/MyDrive/semeval 17 transformer weights/neutro-mpnet.004.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC_29cAPgYuC"
      },
      "source": [
        "answer = model.predict([val_encodings[\"input_ids\"],val_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRs4QzpUgsV9"
      },
      "source": [
        "print(X_val[0])\n",
        "print(Y_oh_val[0])\n",
        "print(labels_val[0])\n",
        "print(\"******************************************\")\n",
        "print(len(answer),len(answer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtvboifWhk61"
      },
      "source": [
        "Counter(Y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY8GSPN72Vz5",
        "outputId": "6cebf158-e54c-4a4d-ab05-a783bc9fb6ca"
      },
      "source": [
        "# used for querying\n",
        "count_sl = 0\n",
        "count_pos = 0\n",
        "count_not = 0\n",
        "pred = []\n",
        "text = df_val[2]\n",
        "\n",
        "temp = 0\n",
        "for i in range(0,len(X_val)):\n",
        "    num = np.argmax(answer[i])\n",
        "    pred.append(num)\n",
        "\n",
        "print(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6L2ROGrg_g3"
      },
      "source": [
        "Counter(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Y5xW8QmeVgS"
      },
      "source": [
        "Counter(Y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6p0jkeeT6Tv"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_val, predictions=pred, dtype=tf.dtypes.int32)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJWkTDiqh_cx"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(con_mat, annot=True,cmap=plt.cm.Spectral,fmt='d',xticklabels=[\"Neutral\",\"Positive\",\"Negative\"], yticklabels=[\"Neutral\",\"Positive\",\"Negative\"])\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zPYBs34iRBA"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(Y_val, pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESQfLwdAhqU0"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(Y_val, pred, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qx-oEbGjPOgG"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['Neutral', 'Positive', 'Negative']\n",
        "print(classification_report(Y_val, pred, digits=3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cLe7eJ_RkEl"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_val, pred, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGRT6Ohsgttp"
      },
      "source": [
        "<h3>Clustering</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIo8_drjrt5o"
      },
      "source": [
        "pip install plotly==4.5.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdYWV8oUry_I"
      },
      "source": [
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "import plotly.express as px"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caQymOSkNzc8"
      },
      "source": [
        "flag = []\n",
        "count = 0\n",
        "\n",
        "positive = []\n",
        "negative = []\n",
        "neutral = []\n",
        "\n",
        "\n",
        "for i in range(0,len(pred)):\n",
        "    count = count + 1\n",
        "    neutral.append(answer[i][0])\n",
        "    positive.append(answer[i][1])\n",
        "    negative.append(answer[i][2])\n",
        "\n",
        "\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iokLmIsCwe-E"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(pred)):\n",
        "    if pred[i] == 0:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if pred[i] == 1:\n",
        "      pred_colour.append(\"Positive\")\n",
        "    if pred[i] == 2:\n",
        "      pred_colour.append(\"Negative\")\n",
        "\n",
        "test_df = pd.DataFrame({'positive':positive, 'negative':negative, 'neutral':neutral, 'Prediction':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='positive', y='negative', z='neutral', color='Prediction')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 0.7,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'})\n",
        "fig.update_layout(width = 700)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huptAtFhvSF6"
      },
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQKewYj1gcBa"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.spatial.distance import cosine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQItgti4itKf"
      },
      "source": [
        "<h5>SVNS</h5>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XECwRJ1Kfw-m"
      },
      "source": [
        "<h3>Middle Layer</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H7Y4oZQdjbd"
      },
      "source": [
        "model.layers[-3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loTB0YxCcAir"
      },
      "source": [
        "with strategy.scope():\n",
        "    cl_model = keras.Model(model.input, model.layers[-3].output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XGbRzE2naUt"
      },
      "source": [
        "cl_32 = cl_model.predict([val_encodings[\"input_ids\"],val_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JesTlyFc3TB"
      },
      "source": [
        "kmeans = KMeans(n_clusters=3, random_state=4).fit(cl_32)\n",
        "y_kmeans_batchnorm = kmeans.predict(cl_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbh38cwLeKSj"
      },
      "source": [
        "for i in range(0,len(y_kmeans_batchnorm)):\n",
        "    if(y_kmeans_batchnorm[i] == 0):\n",
        "      y_kmeans_batchnorm[i] = 1\n",
        "    elif(y_kmeans_batchnorm[i] == 1):\n",
        "      y_kmeans_batchnorm[i] = 2\n",
        "    else:\n",
        "      y_kmeans_batchnorm[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xdKo400fmg8"
      },
      "source": [
        "centers_batchnorm = kmeans.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00QwJjYzlbp8"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_val, predictions=y_kmeans_batchnorm)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FlHfZw87fiY"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['Neutral', 'Positive', 'Negative']\n",
        "print(classification_report(Y_val, y_kmeans_batchnorm, digits=3, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3S7O-kfu_qF"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "figure = plt.figure(figsize=(8, 8))\r\n",
        "sns.heatmap(con_mat, annot=True,cmap=plt.cm.Spectral,fmt='d',xticklabels=[\"Neutral\",\"Positive\",\"Negative\"], yticklabels=[\"Neutral\",\"Positive\",\"Negative\"])\r\n",
        "plt.tight_layout()\r\n",
        "plt.ylabel('True label')\r\n",
        "plt.xlabel('Predicted label')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR0yDPLli7mL"
      },
      "source": [
        "svns_neu_bn = []\n",
        "for i in range(0,len(Y_val)):\n",
        "    neu = cosine(cl_32[i], centers_batchnorm[2])/2\n",
        "    svns_neu_bn.append(1-neu)\n",
        "print(len(svns_neu_bn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W0ENjp9jQd6"
      },
      "source": [
        "svns_pos_bn = []\n",
        "for i in range(0,len(Y_val)):\n",
        "    pos = cosine(cl_32[i], centers_batchnorm[0])/2\n",
        "    svns_pos_bn.append(1-pos)\n",
        "print(len(svns_pos_bn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiciVYGUjpvW"
      },
      "source": [
        "svns_neg_bn = []\n",
        "for i in range(0,len(Y_val)):\n",
        "    neg = cosine(cl_32[i], centers_batchnorm[1])/2\n",
        "    svns_neg_bn.append(1-neg)\n",
        "print(len(svns_neg_bn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr5qnwoN8142"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(pred)):\n",
        "    if y_kmeans_batchnorm[i] == 0:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_batchnorm[i] == 1:\n",
        "      pred_colour.append(\"Positive\")\n",
        "    if y_kmeans_batchnorm[i] == 2:\n",
        "      pred_colour.append(\"Negative\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Positive':svns_pos_bn, 'SVNS Negative':svns_neg_bn, 'SVNS Neutral':svns_neu_bn, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Positive', y='SVNS Negative', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'})\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLrF6WW-wffo"
      },
      "source": [
        "<h3>GRU</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZcqhU1PwjBb"
      },
      "source": [
        "model.layers[-5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEWlVd3zwi9D"
      },
      "source": [
        "with strategy.scope():\n",
        "    cl_model = keras.Model(model.input, (model.layers[-5].output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujS-Tn63oNRE"
      },
      "source": [
        "cl_32 = cl_model.predict([val_encodings[\"input_ids\"],val_encodings[\"attention_mask\"]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrjQrYPiwi7J"
      },
      "source": [
        "kmeans = KMeans(n_clusters=3, random_state=4).fit(cl_32)\n",
        "y_kmeans_gru = kmeans.predict(cl_32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtD1cSZ9wi31"
      },
      "source": [
        "for i in range(0,len(y_kmeans_gru)):\n",
        "    if(y_kmeans_gru[i] == 0):\n",
        "      y_kmeans_gru[i] = 1\n",
        "    elif(y_kmeans_gru[i] == 1):\n",
        "      y_kmeans_gru[i] = 2\n",
        "    else:\n",
        "      y_kmeans_gru[i] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFh36FsDwi1H"
      },
      "source": [
        "centers_gru = kmeans.cluster_centers_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU0BXY29SWok"
      },
      "source": [
        "con_mat = tf.math.confusion_matrix(labels=Y_val, predictions=y_kmeans_gru)\n",
        "print(con_mat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3M9WNy9vbML"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "figure = plt.figure(figsize=(8, 8))\r\n",
        "sns.set(font_scale=1.5)\r\n",
        "sns.heatmap(con_mat, annot=True,cmap=plt.cm.Spectral,fmt='d',xticklabels=[\"Neutral\",\"Positive\",\"Negative\"], yticklabels=[\"Neutral\",\"Positive\",\"Negative\"])\r\n",
        "plt.tight_layout()\r\n",
        "plt.ylabel('True label')\r\n",
        "plt.xlabel('Predicted label')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpEznqf6w_YC"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['Neutral', 'Positive', 'Negative']\n",
        "print(classification_report(Y_val, y_kmeans_gru, digits=3, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pn7Pb_Cw_V5"
      },
      "source": [
        "svns_neu_gru = []\n",
        "for i in range(0,len(Y_val)):\n",
        "    neu = cosine(cl_32[i], centers_gru[2])/2\n",
        "    svns_neu_gru.append(1-neu)\n",
        "print(len(svns_neu_gru))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfwUr7T-w_Q4"
      },
      "source": [
        "svns_pos_gru = []\n",
        "for i in range(0,len(Y_val)):\n",
        "    pos = cosine(cl_32[i], centers_gru[0])/2\n",
        "    svns_pos_gru.append(1-pos)\n",
        "print(len(svns_pos_gru))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8yEsi7cxNVL"
      },
      "source": [
        "svns_neg_gru = []\n",
        "for i in range(0,len(Y_val)):\n",
        "    neg = cosine(cl_32[i], centers_gru[1])/2\n",
        "    svns_neg_gru.append(1-neg)\n",
        "print(len(svns_neg_gru))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3lJuVOp-7yu"
      },
      "source": [
        "pred_colour = []\n",
        "for i in range(0,len(pred)):\n",
        "    if y_kmeans_gru[i] == 0:\n",
        "      pred_colour.append(\"Neutral\")\n",
        "    if y_kmeans_gru[i] == 1:\n",
        "      pred_colour.append(\"Positive\")\n",
        "    if y_kmeans_gru[i] == 2:\n",
        "      pred_colour.append(\"Negative\")\n",
        "\n",
        "test_df = pd.DataFrame({'SVNS Positive':svns_pos_gru, 'SVNS Negative':svns_neg_gru, 'SVNS Neutral':svns_neu_gru, 'Labels:':pred_colour})\n",
        "\n",
        "fig = px.scatter_3d(test_df, x='SVNS Positive', y='SVNS Negative', z='SVNS Neutral', color='Labels:')\n",
        "fig.update_traces(\n",
        "    marker={\n",
        "        'size': 1,\n",
        "        'opacity': 1,\n",
        "        'colorscale' : 'viridis',\n",
        "    }\n",
        ")\n",
        "fig.update_layout(legend= {'itemsizing': 'constant'})\n",
        "fig.update_layout(width = 850, height = 750)\n",
        "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6riKa1r1fQt8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}